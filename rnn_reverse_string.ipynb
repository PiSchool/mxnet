{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from random import choice, randrange\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "ctx=mx.cpu(0)\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary=list(\"ace\")\n",
    "EOS='§'\n",
    "SOS='#'\n",
    "vocabulary.append(EOS)\n",
    "vocabulary.append(SOS)\n",
    "vocab_size=len(vocabulary)\n",
    "MAX_STRING_LEN = 10\n",
    "MAX_INPUST_LEN = 100\n",
    "num_hidden=30\n",
    "embed_size=256\n",
    "batch_size=26\n",
    "int2char = {i:c for i,c in enumerate(vocabulary)}\n",
    "char2int = {c:i for i,c in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'a', 1: 'c', 2: 'e', 3: '§', 4: '#'}\n",
      "vocab size: 5\n"
     ]
    }
   ],
   "source": [
    "print(int2char)\n",
    "print(\"vocab size: \"+str(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strings(min_len, max_len):\n",
    "    random_length = randrange(min_len, max_len)\n",
    "    random_char_list = [choice(vocabulary[:-2]) for _ in range(random_length)]\n",
    "    random_string = ''.join(random_char_list) \n",
    "    return SOS+random_string+EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#accaeeae§'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_strings(4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2ints(string):\n",
    "    return [char2int[char] for char in string]\n",
    "\n",
    "def ints2text(numbers):\n",
    "    return ''.join([int2char[num] for num in numbers])\n",
    "\n",
    "def int2onehot(numbers):\n",
    "    return mx.nd.one_hot(mx.nd.array(numbers),vocab_size)\n",
    "\n",
    "def onehot2int(matrix):\n",
    "    fin=[]\n",
    "    for vec in matrix:\n",
    "        fin.append(int(vec.argmax(axis=0).asnumpy().tolist()[0]))\n",
    "    return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ecceeaacceaaecaacee§ 21\n"
     ]
    }
   ],
   "source": [
    "string=generate_strings(19,20)\n",
    "print(string, len(string))\n",
    "assert ints2text(text2ints(string)) == string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 1, 2, 1, 1, 1, 1, 1, 3]\n",
      "[4, 1, 1, 1, 1, 1, 2, 1, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "train_set = [text2ints(generate_strings(MAX_STRING_LEN-2, MAX_STRING_LEN-1)) for _ in range(3000)]\n",
    "inverse_train_set = [[char2int[SOS]]+sentence[1:-1][::-1]+[char2int[EOS]] for sentence in train_set]\n",
    "eval_set = [text2ints(generate_strings(MAX_STRING_LEN-2, MAX_STRING_LEN-1)) for _ in range(100)]\n",
    "inverse_eval_set = [[char2int[SOS]]+sentence[1:-1][::-1]+[char2int[EOS]] for sentence in eval_set]\n",
    "\n",
    "#print(train_set[0])\n",
    "#print(inverse_train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = mx.io.NDArrayIter(\n",
    "    data=mx.nd.one_hot(mx.nd.array(train_set),vocab_size),\n",
    "    label=mx.nd.one_hot(mx.nd.array(inverse_train_set),vocab_size),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "eval_iter = mx.io.NDArrayIter(\n",
    "    data=mx.nd.one_hot(mx.nd.array(eval_set),vocab_size),\n",
    "    label=mx.nd.one_hot(mx.nd.array(inverse_eval_set),vocab_size),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sym_gen(seq_len):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.Variable('data')\n",
    "label = mx.sym.Variable('softmax_label')\n",
    "\n",
    "embed = mx.sym.Embedding(\n",
    "    data=data,\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embed_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'concat4_output': (26, 60)}\n",
      "{'concat5_output': (26, 60, 30)}\n"
     ]
    }
   ],
   "source": [
    "bi_cell = mx.rnn.BidirectionalCell(\n",
    "    mx.rnn.GRUCell(num_hidden=num_hidden, prefix=\"gru1_\"),\n",
    "    mx.rnn.GRUCell(num_hidden=num_hidden, prefix=\"gru2_\"),\n",
    "    output_prefix=\"bi_\"\n",
    ")\n",
    "\n",
    "encoder = mx.rnn.ResidualCell(bi_cell)\n",
    "        \n",
    "_, encoder_state = encoder.unroll(\n",
    "    length=MAX_STRING_LEN,\n",
    "    inputs=embed,\n",
    "    merge_outputs=False\n",
    ")\n",
    "\n",
    "encoder_state = mx.sym.concat(encoder_state[0][0],encoder_state[1][0])\n",
    "print(mx.symbol_doc.SymbolDoc.get_output_shape(encoder_state, data=(batch_size,MAX_STRING_LEN,vocab_size)))\n",
    "\n",
    "\n",
    "decoder = mx.rnn.GRUCell(num_hidden=num_hidden)\n",
    "\n",
    "rnn_output, decoder_state = decoder.unroll(\n",
    "    length=num_hidden*2,\n",
    "    inputs=encoder_state,\n",
    "    merge_outputs=True\n",
    ")\n",
    "print(mx.symbol_doc.SymbolDoc.get_output_shape(rnn_output, data=(batch_size,MAX_STRING_LEN,vocab_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flatten5_output': (26, 1800)}\n",
      "{'activation5_output': (26, 50)}\n",
      "{'reshape5_output': (26, 10, 5)}\n"
     ]
    }
   ],
   "source": [
    "flat=mx.sym.Flatten(data=rnn_output)\n",
    "print(mx.symbol_doc.SymbolDoc.get_output_shape(flat, data=(batch_size,MAX_STRING_LEN,vocab_size)))\n",
    "\n",
    "fc1=mx.sym.FullyConnected(\n",
    "    data=flat,\n",
    "    num_hidden=MAX_STRING_LEN*vocab_size\n",
    ")\n",
    "#drop=mx.sym.Dropout(data=fc1, p=0.5)\n",
    "act=mx.sym.Activation(data=fc1, act_type='relu')\n",
    "\n",
    "print(mx.symbol_doc.SymbolDoc.get_output_shape(act, data=(batch_size,MAX_STRING_LEN,vocab_size)))\n",
    "\n",
    "out = mx.sym.Reshape(data=act, shape=((0,MAX_STRING_LEN,vocab_size)))\n",
    "\n",
    "#out=mx.sym.round(out)\n",
    "\n",
    "print(mx.symbol_doc.SymbolDoc.get_output_shape(out, data=(batch_size,MAX_STRING_LEN,vocab_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mx.sym.LinearRegressionOutput(data=out, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Batch [32]\tSpeed: 478.69 samples/sec\taccuracy=0.813706\n",
      "INFO:root:Epoch[0] Batch [64]\tSpeed: 467.91 samples/sec\taccuracy=0.818029\n",
      "INFO:root:Epoch[0] Batch [96]\tSpeed: 472.84 samples/sec\taccuracy=0.825264\n",
      "INFO:root:Epoch[0] Train-accuracy=0.829957\n",
      "INFO:root:Epoch[0] Time cost=6.292\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.835577\n",
      "INFO:root:Epoch[1] Batch [32]\tSpeed: 483.88 samples/sec\taccuracy=0.837832\n",
      "INFO:root:Epoch[1] Batch [64]\tSpeed: 478.76 samples/sec\taccuracy=0.848606\n",
      "INFO:root:Epoch[1] Batch [96]\tSpeed: 503.25 samples/sec\taccuracy=0.859519\n",
      "INFO:root:Epoch[1] Train-accuracy=0.866518\n",
      "INFO:root:Epoch[1] Time cost=6.214\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.863269\n",
      "INFO:root:Epoch[2] Batch [32]\tSpeed: 515.22 samples/sec\taccuracy=0.870443\n",
      "INFO:root:Epoch[2] Batch [64]\tSpeed: 495.21 samples/sec\taccuracy=0.881923\n",
      "INFO:root:Epoch[2] Batch [96]\tSpeed: 489.35 samples/sec\taccuracy=0.891322\n",
      "INFO:root:Epoch[2] Train-accuracy=0.893887\n",
      "INFO:root:Epoch[2] Time cost=6.026\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.886154\n",
      "INFO:root:Epoch[3] Batch [32]\tSpeed: 495.09 samples/sec\taccuracy=0.896457\n",
      "INFO:root:Epoch[3] Batch [64]\tSpeed: 474.40 samples/sec\taccuracy=0.895072\n",
      "INFO:root:Epoch[3] Batch [96]\tSpeed: 481.50 samples/sec\taccuracy=0.896923\n",
      "INFO:root:Epoch[3] Train-accuracy=0.896599\n",
      "INFO:root:Epoch[3] Time cost=6.391\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.888462\n",
      "INFO:root:Epoch[4] Batch [32]\tSpeed: 481.03 samples/sec\taccuracy=0.897319\n",
      "INFO:root:Epoch[4] Batch [64]\tSpeed: 493.66 samples/sec\taccuracy=0.896514\n",
      "INFO:root:Epoch[4] Batch [96]\tSpeed: 477.81 samples/sec\taccuracy=0.896611\n",
      "INFO:root:Epoch[4] Train-accuracy=0.895547\n",
      "INFO:root:Epoch[4] Time cost=6.285\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.909038\n",
      "INFO:root:Epoch[5] Batch [32]\tSpeed: 506.57 samples/sec\taccuracy=0.899301\n",
      "INFO:root:Epoch[5] Batch [64]\tSpeed: 475.60 samples/sec\taccuracy=0.897933\n",
      "INFO:root:Epoch[5] Batch [96]\tSpeed: 484.27 samples/sec\taccuracy=0.897260\n",
      "INFO:root:Epoch[5] Train-accuracy=0.898543\n",
      "INFO:root:Epoch[5] Time cost=6.250\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.915000\n",
      "INFO:root:Epoch[6] Batch [32]\tSpeed: 497.04 samples/sec\taccuracy=0.899510\n",
      "INFO:root:Epoch[6] Batch [64]\tSpeed: 330.48 samples/sec\taccuracy=0.899038\n",
      "INFO:root:Epoch[6] Batch [96]\tSpeed: 434.82 samples/sec\taccuracy=0.897043\n",
      "INFO:root:Epoch[6] Train-accuracy=0.900648\n",
      "INFO:root:Epoch[6] Time cost=7.186\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.897692\n",
      "INFO:root:Epoch[7] Batch [32]\tSpeed: 507.94 samples/sec\taccuracy=0.898765\n",
      "INFO:root:Epoch[7] Batch [64]\tSpeed: 474.95 samples/sec\taccuracy=0.899062\n",
      "INFO:root:Epoch[7] Batch [96]\tSpeed: 498.67 samples/sec\taccuracy=0.898053\n",
      "INFO:root:Epoch[7] Train-accuracy=0.900729\n",
      "INFO:root:Epoch[7] Time cost=6.167\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.884808\n"
     ]
    }
   ],
   "source": [
    "model = mx.module.Module(net)\n",
    "model.fit(\n",
    "    train_data=train_iter,\n",
    "    eval_data=eval_iter,\n",
    "    eval_metric = 'acc',\n",
    "    optimizer=mx.optimizer.Adam(rescale_grad=1/batch_size),\n",
    "    #optimizer_params={'learning_rate':0.001, 'momentum':0.9},\n",
    "    initializer=mx.initializer.Xavier(),\n",
    "    batch_end_callback=mx.callback.Speedometer(batch_size, 32),\n",
    "    num_epoch=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [text2ints(generate_strings(MAX_STRING_LEN-2, MAX_STRING_LEN-1)) for _ in range(5)]\n",
    "\n",
    "#print(test_set[0])\n",
    "#print(ints2text(test_set[0]))\n",
    "\n",
    "inverse_test_set = [[char2int[SOS]]+sentence[1:-1][::-1]+[char2int[EOS]] for sentence in test_set]    \n",
    "\n",
    "#print(inverse_test_set[0])\n",
    "#print(ints2text(inverse_test_set[0]))\n",
    "    \n",
    "#print(mx.nd.one_hot(mx.nd.array(test_set[0]),vocab_size))\n",
    "#print(mx.nd.one_hot(mx.nd.array(inverse_test_set[0]),vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "#eecceeae§\n",
      "#eaeeccee§\n",
      "--------------------\n",
      "1\n",
      "#aaceeeca§\n",
      "#aceeecaa§\n",
      "--------------------\n",
      "2\n",
      "#aeeaaecc§\n",
      "#cceaaeea§\n",
      "--------------------\n",
      "3\n",
      "#ecaaeecc§\n",
      "#cceeaace§\n",
      "--------------------\n",
      "4\n",
      "#aeaaaacc§\n",
      "#ccaaaaea§\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "test_iter = mx.io.NDArrayIter(\n",
    "    data=mx.nd.one_hot(mx.nd.array(test_set),vocab_size),\n",
    "    label=mx.nd.one_hot(mx.nd.array(inverse_test_set),vocab_size),\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "#test_iter.reset()\n",
    "predictions=model.predict(test_iter)\n",
    "\n",
    "for i,pred in enumerate(predictions):\n",
    "    print(i)\n",
    "    print(ints2text((test_set[i])))\n",
    "    print(ints2text(onehot2int(mx.ndarray.round(predictions[i]))))\n",
    "    print(\"--------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
