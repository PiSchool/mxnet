{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "ctx=mx.cpu(0)\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "from word_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden=64\n",
    "embed_size=64\n",
    "batch_size=100\n",
    "dataset_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, inverse_train_set, eval_set, inverse_eval_set, max_string_len = generate_train_eval_sets(dataset_size=dataset_size)\n",
    "\n",
    "train_iter = generate_OH_iterator(train_set=train_set, label_set=inverse_train_set, batch_size=batch_size, max_len=max_string_len)\n",
    "eval_iter = generate_OH_iterator(train_set=eval_set, label_set=inverse_eval_set, batch_size=batch_size, max_len=max_string_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mx.sym.Variable('data')\n",
    "label = mx.sym.Variable('softmax_label')\n",
    "\n",
    "embed = mx.sym.Embedding(\n",
    "    data=data,\n",
    "    input_dim=vocab_size_train, # when one hot, lenght of vocabulary; when floats, lenght of array\n",
    "    output_dim=embed_size\n",
    ")\n",
    "\n",
    "bi_cell = mx.rnn.BidirectionalCell(\n",
    "    mx.rnn.GRUCell(num_hidden=num_hidden, prefix=\"gru1_\"),\n",
    "    mx.rnn.GRUCell(num_hidden=num_hidden, prefix=\"gru2_\"),\n",
    "    output_prefix=\"bi_\"\n",
    ")\n",
    "\n",
    "encoder = mx.rnn.ResidualCell(bi_cell)\n",
    "        \n",
    "_, encoder_state = encoder.unroll(\n",
    "    length=max_string_len,\n",
    "    inputs=embed,\n",
    "    merge_outputs=False\n",
    ")\n",
    "\n",
    "encoder_state = mx.sym.concat(encoder_state[0][0],encoder_state[1][0])\n",
    "\n",
    "decoder = mx.rnn.GRUCell(num_hidden=num_hidden*2)\n",
    "\n",
    "rnn_output, decoder_state = decoder.unroll(\n",
    "    length=num_hidden*2,\n",
    "    inputs=encoder_state,\n",
    "    merge_outputs=True\n",
    ")\n",
    "\n",
    "flat=mx.sym.Flatten(data=rnn_output)\n",
    "\n",
    "fc=mx.sym.FullyConnected(\n",
    "    data=flat,\n",
    "    num_hidden=max_string_len*vocab_size_train\n",
    ")\n",
    "#drop=mx.sym.Dropout(data=fc, p=0.5)\n",
    "act=mx.sym.Activation(data=fc, act_type='relu')\n",
    "\n",
    "\n",
    "out = mx.sym.Reshape(data=act, shape=((0,max_string_len,vocab_size_train)))\n",
    "\n",
    "#out=mx.sym.round(out)\n",
    "\n",
    "net = mx.sym.LinearRegressionOutput(data=out, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = mx.module.Module(net)\n",
    "model.fit(\n",
    "    train_data=train_iter,\n",
    "    eval_data=eval_iter,\n",
    "    eval_metric = 'acc',\n",
    "    optimizer=mx.optimizer.Adam(rescale_grad=1/batch_size),\n",
    "    #optimizer_params={'learning_rate':0.001, 'momentum':0.9},\n",
    "    initializer=mx.initializer.Xavier(),\n",
    "    batch_end_callback=mx.callback.Speedometer(batch_size, 10),\n",
    "    num_epoch=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "testset_size=100\n",
    "\n",
    "test_set, inverse_test_set, _, _, max_len = generate_train_eval_sets(dataset_size=testset_size, max_len=149)\n",
    "test_iter = generate_iterator(train_set=test_set, label_set=inverse_test_set, batch_size=1)\n",
    "\n",
    "predictions=model.predict(test_iter)\n",
    "\n",
    "match_count=0\n",
    "for i,pred in enumerate(predictions):\n",
    "    matched = ints2text(onehot2int(mx.ndarray.round(predictions[i]))) == ints2text(inverse_test_set[i])\n",
    "    if matched:\n",
    "        match_count+=1\n",
    "    else:       \n",
    "        print(i)\n",
    "        inverse=ints2text(inverse_test_set[i])\n",
    "        print(inverse)\n",
    "        inverse_pred=ints2text(onehot2int(mx.ndarray.round(predictions[i])))\n",
    "        print(inverse_pred)\n",
    "        print(matched)\n",
    "        for i,s in enumerate(difflib.ndiff(inverse, inverse_pred)):\n",
    "            if s[0]==' ': continue\n",
    "            elif s[0]=='-':\n",
    "                print(u'Delete \"{}\" from position {}'.format(s[-1],i))\n",
    "            elif s[0]=='+':\n",
    "                print(u'Add \"{}\" to position {}'.format(s[-1],i))    \n",
    "        print(\"--------------------\")\n",
    "\n",
    "print(\"Matched %d/%d times\" % (match_count,testset_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
