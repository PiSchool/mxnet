{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>TACOTRON</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "from IPython.display import clear_output\n",
    "ctx= mx.cpu()\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import audio_process\n",
    "import traceback\n",
    "import subprocess\n",
    "import math\n",
    "from params import Hyperparams as hp \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> DATA SETUP </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden = hp.embed_size\n",
    "reduction_factor=hp.r\n",
    "emb_size=hp.embed_size\n",
    "batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_vocabulary(texts_list):    \n",
    "    # get unique chars and put into a list\n",
    "    return list(set(''.join(texts_list)))\n",
    "    \n",
    "\n",
    "def generate_chars2numbers_mappings(vocabulary):\n",
    "    # create a chars <-> numbers mappings\n",
    "    char2index = {char:i for i,char in enumerate(vocabulary)}\n",
    "    index2char = {i:char for i,char in enumerate(vocabulary)}\n",
    "    \n",
    "    return char2index,index2char\n",
    "\n",
    "\n",
    "def text2numbers(texts_list,char2index_mapping):\n",
    "    numerical_texts=[]\n",
    "    for text in texts_list:\n",
    "        numerical_texts.append([char2index_mapping[char] for char in text])\n",
    "    return numerical_texts\n",
    "\n",
    "def open_data(input_file_path):\n",
    "      \n",
    "    texts, sound_files = [], []\n",
    "    \n",
    "    reader = csv.reader(codecs.open(input_file_path, 'rb', 'utf-8'))\n",
    "    for row in reader:\n",
    "        sound_filename, text = row\n",
    "        sound_file = hp.sound_fpath +\"/\"+ sound_filename + \".wav\"\n",
    "        text = re.sub(r\"[^ a-z']\", \"\", text.strip().lower())\n",
    "         \n",
    "        texts.append(text)\n",
    "        sound_files.append(sound_file)\n",
    "             \n",
    "    return texts, sound_files\n",
    "# Returns: one-hot-encoded-text, linear spectrum, mel spectrum\n",
    "# Shapes: (data_length, ?, ?) , (data_length, (n_fft/2)+1, ceil(max_audio_length/hop_size)), (data_length, n_mels, ceil(max_audio_length/hop_size))\n",
    "def generate_text_spectra(texts_list, sound_labels):\n",
    "    \n",
    "    assert len(sound_labels) == len(texts_list)\n",
    "    \n",
    "    print(\"Generating spectrograms\")\n",
    "    \n",
    "    #tuples of wav and sr of that wav. wav is a 1D floats vector\n",
    "    wavs_srs = [audio_process.load_wave(sound_clip) for sound_clip in sound_labels]\n",
    "    longest_wav_sr = (max(wavs_srs, key= lambda wav: len(wav[0])))\n",
    "    #save the longest audio file length\n",
    "    max_samples_length=(len(longest_wav_sr[0]))\n",
    "    print(\"max audio sample length:\",max_samples_length)\n",
    "\n",
    "    #prepare the data structure for save all the spectra\n",
    "    spectra_lin = mx.ndarray.zeros((len(sound_labels),1+(hp.n_fft//2),math.ceil(max_samples_length/hp.hop_length)))\n",
    "    spectra_mel = mx.ndarray.zeros((len(sound_labels),hp.n_mels,math.ceil(max_samples_length/hp.hop_length)))\n",
    "    print(\"Padding audio and compute mel and lin spectra..\")\n",
    "    for indx,wav_sr in enumerate(wavs_srs):\n",
    "        wav = wav_sr[0]\n",
    "        wav_length = len(wav)\n",
    "#         print(\"wav l\",w_length)\n",
    "        diff = max_samples_length-wav_length\n",
    "#         print(\"num of zeros to add\",diff)\n",
    "        padded = np.append(wav,np.zeros(diff))\n",
    "        # get the spectrum from the padded sound\n",
    "        spectrum_lin, spectrum_mel=(audio_process.do_spectrogram(y=padded,sr=hp.sr))\n",
    "#         print(padded_spectrum_lin.shape)\n",
    "        # save into the ndarray\n",
    "        spectra_lin[indx,:,:]=spectrum_lin[:,:]\n",
    "        spectra_mel[indx,:,:]=spectrum_mel[:,:]\n",
    "    \n",
    "    \n",
    "    print(\"Processing text..\")\n",
    "    vocabulary = generate_vocabulary(texts_list)\n",
    "    vocab_size=len(vocabulary)\n",
    "    char2index,index2char = generate_chars2numbers_mappings(vocabulary)\n",
    "\n",
    "    print(\"Converting text to integers..\")\n",
    "    texts_numerical = text2numbers(texts_list,char2index)\n",
    "    # simulate a different sequence length\n",
    "#   /D E L E T E M E/ \n",
    "    texts_numerical[4]=np.concatenate((texts_numerical[4],[8,9]))\n",
    "#   /D E L E T E M E/\n",
    "\n",
    "    longest_sequence = (max(texts_numerical, key= lambda seq: len(seq)))\n",
    "    longest_sequence_len=len(longest_sequence)\n",
    "    print(\"Pad sequences to\",longest_sequence_len,\"..\")\n",
    "    # helper function for the lambda expression\n",
    "    def _padseq(seq,max_len):\n",
    "        diff=max_len-len(seq)\n",
    "        if diff>0: \n",
    "            # SHITTY USELESS MXNET API. CANNOT CONCAT A NON-EMPTY WITH EMPTY ARRAY. \n",
    "            # EDIT: use numpy now. Still using this condition for safety\n",
    "            pad = np.zeros(diff)-1\n",
    "            seq=np.append(seq,[pad])\n",
    "        return seq\n",
    "    \n",
    "    padded_sequences = mx.nd.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda seq: _padseq(seq,longest_sequence_len), texts_numerical\n",
    "            )\n",
    "        )\n",
    "    )   \n",
    "    \n",
    "    texts_one_hot=mx.ndarray.one_hot(padded_sequences,vocab_size)\n",
    "    \n",
    "    return texts_one_hot, spectra_lin, spectra_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating spectrograms\n",
      "max audio sample length: 17567\n",
      "Padding audio and compute mel and lin spectra..\n",
      "Processing text..\n",
      "Converting text to integers..\n",
      "Pad sequences to 7 ..\n",
      "I will take those for eval: [26 25 10  1  4]\n",
      "..and the remaining for train: [ 0  2  3  5  6  7  8  9 11 12 13 14 15 16 17 18 19 20 21 22 23 24 27 28 29\n",
      " 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49] \n",
      "\n",
      "train data shape: (45, 80, 176) train label shape: (45, 1025, 176)\n",
      "eval data shape: (5, 80, 176) eval label shape: (5, 1025, 176) \n",
      "\n",
      "Populating traindata iterator\n",
      "Populating evaldata iterator\n",
      "Batch size= 2 due few data in dummy train set\n",
      "DataBatch: data shapes: [(2, 80, 176)] label shapes: [(2, 1025, 176)]\n"
     ]
    }
   ],
   "source": [
    "def get_iterators(data='train_data/dataset.csv'):\n",
    "    texts_list, sound_files_list = open_data(data)\n",
    "    size=len(sound_files_list)\n",
    "\n",
    "    texts_one_hot, spectra_lin, spectra_mel = generate_text_spectra(texts_list, sound_files_list)\n",
    "\n",
    "    # get 10% of dataset as eval data \n",
    "    eval_indxs = (np.random.randint(0, high=size, size=size//10))\n",
    "    # remaining indexes for the train\n",
    "    train_indxs = np.setdiff1d(np.arange(size),eval_indxs)\n",
    "\n",
    "    print(\"I will take those for eval:\",eval_indxs)\n",
    "    print(\"..and the remaining for train:\",train_indxs,\"\\n\")\n",
    "\n",
    "    #take from the array (1st arg) the indexes of the first dimension specified by the 2nd arg\n",
    "    #train_txt take the one_hot matrices\n",
    "    train_txt_data = mx.ndarray.take(texts_one_hot,mx.nd.array(train_indxs))\n",
    "    eval_txt_data = mx.ndarray.take(texts_one_hot,mx.nd.array(eval_indxs))\n",
    "\n",
    "    train_data = mx.ndarray.take(spectra_mel,mx.nd.array(train_indxs))\n",
    "    train_label = mx.ndarray.take(spectra_lin,mx.nd.array(train_indxs))\n",
    "\n",
    "    eval_data = mx.ndarray.take(spectra_mel,mx.nd.array(eval_indxs))\n",
    "    eval_label = mx.ndarray.take(spectra_lin,mx.nd.array(eval_indxs))\n",
    "\n",
    "    print(\"train data shape:\",train_data.shape,\"train label shape:\",train_label.shape)\n",
    "    print(\"eval data shape:\", eval_data.shape,\"eval label shape:\",eval_label.shape,\"\\n\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Populating traindata iterator\")\n",
    "        traindata_iterator = mx.io.NDArrayIter(data={'mel_spectrogram':train_data},\n",
    "                                label={'linear_spectrogram':train_label},\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "        print(\"Populating evaldata iterator\")\n",
    "        evaldata_iterator = mx.io.NDArrayIter(data={'mel_spectrogram':eval_data},\n",
    "                                label={'linear_spectrogram':eval_label},\n",
    "                                batch_size=batch_size)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "#     for batch in traindata_iterator:\n",
    "#         print(batch.data[0].asnumpy())\n",
    "#         print(batch.data[0].shape)\n",
    "    \n",
    "    return traindata_iterator,evaldata_iterator\n",
    "\n",
    "\n",
    "b=get_iterators(hp.text_file)[0].next()\n",
    "print(\"Batch size=\",batch_size,\"due few data in dummy train set\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Modules </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Prenet </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FC-256-ReLU → Dropout(0.5) → FC-128-ReLU → Dropout(0.5)\n",
    "\"\"\"\n",
    "def prenet_pass(data):\n",
    "    fc1 = mx.symbol.FullyConnected(data=data, num_hidden=emb_size, name='prenet_fc1',flatten=False)\n",
    "    act1 = mx.symbol.Activation(data=fc1, act_type='relu', name='prenet_act1')\n",
    "    drop1 = mx.symbol.Dropout(act1, p=0.5, name='prenet_drop1')\n",
    "    \n",
    "    fc2 = mx.symbol.FullyConnected(data=drop1, num_hidden=emb_size//2, name='prenet_fc2', flatten=False)\n",
    "    act2 = mx.symbol.Activation(data=fc2, act_type='relu', name='prenet_act2')\n",
    "    prenet_output = mx.symbol.Dropout(act2, p=0.5, name='prenet_drop2')\n",
    "    \n",
    "    return prenet_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Convolution 1D Bank </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolution bank of K filter\n",
    "def conv1dBank(conv_input, K):\n",
    "    conv=mx.sym.Convolution(data=conv_input, kernel=(1,), num_filter=emb_size//2) #\n",
    "    (conv, mean, var) = mx.sym.BatchNorm(data=conv, output_mean_var=True)\n",
    "    conv = mx.sym.Activation(data=conv, act_type='relu')\n",
    "    for k in range(2, K+1):\n",
    "        convi = mx.sym.Convolution(data=conv_input, kernel=(k,), num_filter=emb_size//2)\n",
    "        (convi, mean, var) = mx.sym.BatchNorm(data=convi, output_mean_var=True)\n",
    "        convi = mx.sym.Activation(data=convi, act_type='relu')\n",
    "        conv = mx.symbol.concat(conv,convi,dim=2)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Highway </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# highway\n",
    "def highway_layer(data):\n",
    "    H= mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=data, num_hidden=emb_size//2, name=\"highway_fcH\"),\n",
    "        act_type=\"relu\"\n",
    "    )\n",
    "    T= mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=data, num_hidden=emb_size//2, bias=mx.sym.Variable('bias'), name=\"highway_fcT\"),\n",
    "        act_type=\"sigmoid\"\n",
    "    )\n",
    "    return  H * T + data * (1.0 - T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> CBHG </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CBHG\n",
    "def CBHG(data,K,proj1_size,proj2_size):\n",
    "    bank = conv1dBank(data,K)\n",
    "#     bank=mx.sym.Convolution(data=conv_input, kernel=(1,), num_filter=emb_size//2)\n",
    "#     for k in range (2,K):\n",
    "#         bank=mx.sym.Convolution(data=bank, kernel=(k,), num_filter=k*(emb_size//2))\n",
    "    \n",
    "    poold_bank = mx.sym.Pooling(data=bank, pool_type='max', kernel=(2,), stride=(1,), name=\"CBHG_pool\")\n",
    "\n",
    "    proj1 = mx.sym.Convolution(data=poold_bank, kernel=(3,), num_filter=proj1_size, name='CBHG_conv1')\n",
    "    (proj1, proj1_mean, proj1_var) = mx.sym.BatchNorm(data=proj1, output_mean_var=True, name='CBHG_batch1')\n",
    "    proj1 = mx.sym.Activation(data=proj1, act_type='relu', name='CBHG_act1')\n",
    "\n",
    "    proj2 = mx.sym.Convolution(proj1, kernel=(3,), num_filter=proj2_size, name='CBHG_conv2')\n",
    "    (proj2, proj2_mean, proj2_var) = mx.sym.BatchNorm(data=proj2, output_mean_var=True, name='CBHG_batch2')\n",
    "    \n",
    "    residual= proj2 + data #How can I do the residual sum with different shapes? \n",
    "\n",
    "    for i in range(4):\n",
    "        residual = highway_layer(residual)\n",
    "    highway_pass = residual\n",
    "   \n",
    "    bidirectional_gru_cell = mx.rnn.BidirectionalCell(\n",
    "        mx.rnn.GRUCell(num_hidden=emb_size//2, prefix='CBHG_gru1'),\n",
    "        mx.rnn.GRUCell(num_hidden=emb_size//2, prefix='CBHG_gru2'),\n",
    "        output_prefix='CBHG_bi_'\n",
    "    )\n",
    "    outputs, states = bidirectional_gru_cell.unroll(1, inputs=highway_pass, merge_outputs=True)\n",
    "    return residual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Encoder </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "def encoder(data):\n",
    "    embed_vector = mx.sym.Embedding(data=data, input_dim=longest_word, output_dim=emb_size, name='encoder_embed')\n",
    "    prenet_output = prenet_pass(embed_vector)\n",
    "    return CBHG(prenet_output,16, emb_size//2, emb_size//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Decoder (stub)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoder\n",
    "def decoder(input_spectrogram,context,reduction_factor):\n",
    "    #embed_vector = mx.sym.Embedding(data=input_spectrogram, input_dim=80, output_dim=emb_size, name='decoder_embed')\n",
    "    prenet_output = prenet_pass(input_spectrogram)\n",
    "        \n",
    "    stack = mx.rnn.SequentialRNNCell()\n",
    "    stack.add(mx.rnn.GRUCell(num_hidden=emb_size,prefix='decoder_layer1_'))\n",
    "    stack.add(mx.rnn.GRUCell(num_hidden=emb_size,prefix='decoder_layer2_'))\n",
    "    \n",
    "    residual_gru_stack = mx.rnn.ResidualCell(stack)\n",
    "    \n",
    "    gru_outputs,states = residual_gru_stack.unroll(length=1,\n",
    "                                               inputs=prenet_output,\n",
    "                                               begin_state=context,\n",
    "                                               merge_outputs=True)\n",
    "\n",
    "    predicted_frames = mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=gru_outputs, num_hidden=80*reduction_factor),\n",
    "        act_type=\"relu\"\n",
    "    )\n",
    "    \n",
    "    return predicted_frames, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test section </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> inference tests on CONV1BANK </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 6 required positional arguments: 'data_names', 'data_shapes', 'data_gen', 'label_names', 'label_shapes', and 'label_gen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-54f8f6036971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSimpleIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 6 required positional arguments: 'data_names', 'data_shapes', 'data_gen', 'label_names', 'label_shapes', and 'label_gen'"
     ]
    }
   ],
   "source": [
    "\n",
    "conv1=mx.sym.Convolution(data=conv_input, kernel=(1,), num_filter=emb_size//2)\n",
    "conv2=mx.sym.Convolution(data=conv_input, kernel=(2,), pad=(3,), num_filter=emb_size//2)\n",
    "conv3=mx.sym.Convolution(data=conv_input, kernel=(3,) , num_filter=emb_size//2)\n",
    "conv4=mx.sym.Convolution(data=conv_input, kernel=(4,) , num_filter=emb_size//2)\n",
    "conv5=mx.sym.Convolution(data=conv_input, kernel=(5,) , num_filter=emb_size//2)\n",
    "conv6=mx.sym.Convolution(data=conv_input, kernel=(6,) , num_filter=emb_size//2)\n",
    "conv6=mx.sym.Convolution(data=conv_input, kernel=(7,) , num_filter=emb_size//2)\n",
    "conv6=mx.sym.Convolution(data=conv_input, kernel=(8,) , num_filter=emb_size//2)\n",
    "\n",
    "\n",
    "print(conv1.infer_shape(mel_spectrogram=mel_spectrogram_shape)[1])\n",
    "print(conv2.infer_shape(mel_spectrogram=mel_spectrogram_shape)[1])\n",
    "print(conv3.infer_shape(mel_spectrogram=mel_spectrogram_shape)[1])\n",
    "print(conv4.infer_shape(mel_spectrogram=mel_spectrogram_shape)[1])\n",
    "print(conv5.infer_shape(mel_spectrogram=mel_spectrogram_shape)[1])\n",
    "print(conv6.infer_shape(mel_spectrogram=mel_spectrogram_shape)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape for prenet : (2, 100, 80)\n",
      "input shape for bank : [(2, 100, 128)]\n",
      "conv1bank output shape: [(2, 128, 126)]\n"
     ]
    }
   ],
   "source": [
    "# Convolution bank of K filter\n",
    "def conv1dBank_1(conv_input, K):\n",
    "    conv=mx.sym.Convolution(data=conv_input, kernel=(3,), num_filter=emb_size//2)\n",
    "    #conv=mx.sym.swapaxes(conv,1,2)\n",
    "    (conv, mean, var) = mx.sym.BatchNorm(data=conv, output_mean_var=True)\n",
    "    conv = mx.sym.Activation(data=conv, act_type='relu')\n",
    "    \n",
    "    #conv2 = mx.sym.Convolution(data=conv_input, kernel=(2,), num_filter=emb_size//2)\n",
    "    #conv = mx.symbol.concat(conv,conv2,dim=2)\n",
    "    #conv3 = mx.sym.Convolution(data=conv_input, kernel=(3,), num_filter=emb_size//2)\n",
    "#     for k in range(2, K+1):\n",
    "#         convi = mx.sym.Convolution(data=conv_input, kernel=(k,), num_filter=emb_size//2)\n",
    "#         convi=mx.sym.swapaxes(convi,1,2)\n",
    "#         (convi, mean, var) = mx.sym.BatchNorm(data=convi, output_mean_var=True)\n",
    "#         convi = mx.sym.Activation(data=convi, act_type='relu')\n",
    "#         conv = mx.symbol.concat(conv,convi,dim=2)\n",
    "    return conv\n",
    "prenet_out = prenet_pass(mel_spectrogram)\n",
    "c1b_args_shape, c1b_out_shape, c1b_aux_shape = conv1dBank_1(prenet_out,8).infer_shape(mel_spectrogram=mel_spectrogram_shape)\n",
    "print(\"input shape for prenet :\",mel_spectrogram_shape)\n",
    "print(\"input shape for bank :\",prenet_out.infer_shape(mel_spectrogram=mel_spectrogram_shape)[1])\n",
    "print(\"conv1bank output shape:\",c1b_out_shape) #[b,num_fil,out_width]\n",
    "#1: 2,128,100|\n",
    "#2: 2,128,99 |concat: 2,128,199|\n",
    "#3: 2,128,98                   |concat:2,128,297\n",
    "#4: 2,128,97...\n",
    "#shape = {\"in_conv1bnk\" : in_conv1bnk_shape}\n",
    "#mx.viz.plot_network(symbol=conv1dBank_1(in_conv1bnk,8), shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> inference tests on CBHG </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> inference tests on CBHG step by step until residual add</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv:\n",
      "c_out_shapes [(2, 1024, 100)]\n",
      "pool:\n",
      "pool_out_shapes [(2, 1024, 99)]\n",
      "proj1\n",
      "proj1_out_shapes [(2, 256, 97)]\n",
      "proj2\n",
      "proj2_out_shapes [(2, 128, 95)]\n",
      "residual\n",
      "infer_shape error. Arguments:\n",
      "  mel_spectrogram: (2, 100, 80)\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Error in operator _plus10: [12:04:36] src/operator/nn/./../tensor/../elemwise_op_common.h:122: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node _plus10 at 1-th input: expected (2,128,95), got (2,128,100)\n\nStack trace returned 10 entries:\n[bt] (0) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f6abaa69bbc]\n[bt] (1) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x293a73) [0x7f6abab7fa73]\n[bt] (2) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x294ab4) [0x7f6abab80ab4]\n[bt] (3) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f6abc9040ee]\n[bt] (4) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x201ac50) [0x7f6abc906c50]\n[bt] (5) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXSymbolInferShape+0x1539) [0x7f6abc895289]\n[bt] (6) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f6adfd45ec0]\n[bt] (7) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f6adfd4587d]\n[bt] (8) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f6adff5a82e]\n[bt] (9) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12265) [0x7f6adff5b265]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d29f66b14758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"residual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mresidual_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_out_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_aux_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_spectrogram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmel_spectrogram_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"residual_arg_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresidual_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"residual_out_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresidual_out_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"residual_aux_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresidual_aux_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/symbol/symbol.py\u001b[0m in \u001b[0;36minfer_shape\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \"\"\"\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_shape_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0marg_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_shape_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/symbol/symbol.py\u001b[0m in \u001b[0;36m_infer_shape_impl\u001b[0;34m(self, partial, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_shape_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_shape_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m             ctypes.byref(complete)))\n\u001b[0m\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             arg_shapes = [\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Error in operator _plus10: [12:04:36] src/operator/nn/./../tensor/../elemwise_op_common.h:122: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node _plus10 at 1-th input: expected (2,128,95), got (2,128,100)\n\nStack trace returned 10 entries:\n[bt] (0) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f6abaa69bbc]\n[bt] (1) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x293a73) [0x7f6abab7fa73]\n[bt] (2) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x294ab4) [0x7f6abab80ab4]\n[bt] (3) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f6abc9040ee]\n[bt] (4) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x201ac50) [0x7f6abc906c50]\n[bt] (5) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXSymbolInferShape+0x1539) [0x7f6abc895289]\n[bt] (6) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f6adfd45ec0]\n[bt] (7) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f6adfd4587d]\n[bt] (8) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f6adff5a82e]\n[bt] (9) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12265) [0x7f6adff5b265]\n"
     ]
    }
   ],
   "source": [
    "K=8\n",
    "# conv=mx.sym.Convolution(data=in_cbhg, kernel=(1,), num_filter=emb_size//2)\n",
    "# (conv, mean, var) = mx.sym.BatchNorm(data=conv, output_mean_var=True)\n",
    "# conv = mx.sym.Activation(data=conv, act_type='relu')\n",
    "# for k in range(2, K+1):\n",
    "#     convi = mx.sym.Convolution(data=in_cbhg, kernel=(k,), num_filter=emb_size//2)\n",
    "#     (convi, mean, var) = mx.sym.BatchNorm(data=convi, output_mean_var=True)\n",
    "#     convi = mx.sym.Activation(data=convi, act_type='relu')\n",
    "#     conv = mx.symbol.concat(conv,convi,dim=2)\n",
    "in_cbhg = prenet_pass(mel_spectrogram)\n",
    "bank=mx.sym.Convolution(data=in_cbhg, kernel=(1,), num_filter=emb_size//2)\n",
    "for k in range (2,K+1):\n",
    "    bank=mx.sym.Convolution(data=bank, kernel=(k,), num_filter=k*(emb_size//2))\n",
    "    \n",
    "\n",
    "poold_bank = mx.sym.Pooling(data=bank, pool_type='max', kernel=(2,), stride=(1,), name=\"CBHG_pool\")\n",
    "\n",
    "proj1 = mx.sym.Convolution(data=poold_bank, kernel=(3,), num_filter=256, name='CBHG_conv1')\n",
    "(proj1, proj1_mean, proj1_var) = mx.sym.BatchNorm(data=proj1, output_mean_var=True, name='CBHG_batch1')\n",
    "proj1 = mx.sym.Activation(data=proj1, act_type='relu', name='CBHG_act1')\n",
    "\n",
    "proj2 = mx.sym.Convolution(proj1, kernel=(3,), num_filter=128, name='CBHG_conv2')\n",
    "(proj2, proj2_mean, proj2_var) = mx.sym.BatchNorm(data=proj2, output_mean_var=True, name='CBHG_batch2')\n",
    "\n",
    "residual= proj2 + mx.sym.swapaxes(in_cbhg,1,2)\n",
    "\n",
    "print(\"conv:\")\n",
    "c_arg_shapes, c_out_shapes, c_aux_shapes=bank.infer_shape(mel_spectrogram=mel_spectrogram_shape)\n",
    "#print(\"c_arg_shapes\",c_arg_shapes)\n",
    "print(\"c_out_shapes\",c_out_shapes)\n",
    "#print(\"c_aux_shapes\",c_aux_shapes)\n",
    "\n",
    "print(\"pool:\")\n",
    "pool_arg_shapes, pool_out_shapes, pool_aux_shapes=poold_bank.infer_shape(mel_spectrogram=mel_spectrogram_shape)\n",
    "#print(\"pool_arg_shapes\",pool_arg_shapes)\n",
    "print(\"pool_out_shapes\",pool_out_shapes)\n",
    "#print(\"pool_aux_shapes\",pool_aux_shapes)\n",
    "\n",
    "print(\"proj1\")\n",
    "proj1_arg_shapes, proj1_out_shapes, proj1_aux_shapes = proj1.infer_shape(mel_spectrogram=mel_spectrogram_shape)\n",
    "#print(\"proj1_arg_shapes\",proj1_arg_shapes)\n",
    "print(\"proj1_out_shapes\",proj1_out_shapes)\n",
    "#print(\"proj1_aux_shapes\",proj1_aux_shapes)\n",
    "\n",
    "print(\"proj2\")\n",
    "proj2_arg_shapes, proj2_out_shapes, proj2_aux_shapes =proj2.infer_shape(mel_spectrogram=mel_spectrogram_shape)\n",
    "#print(\"proj2_arg_shapes\",proj2_arg_shapes)\n",
    "print(\"proj2_out_shapes\",proj2_out_shapes)\n",
    "#print(\"proj2_aux_shapes\",proj2_aux_shapes)\n",
    "\n",
    "print(\"residual\")\n",
    "residual_arg_shapes, residual_out_shapes, residual_aux_shapes = residual.infer_shape(mel_spectrogram=mel_spectrogram_shape)\n",
    "print(\"residual_arg_shapes\",residual_arg_shapes,\"residual_out_shapes\",residual_out_shapes,\"residual_aux_shapes\",residual_aux_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postprocess(input_mel_spectgrograms):\n",
    "    linear_scale_spectrograms=CBHG(input_mel_spectgrograms,8,hp.embed_size,hp.n_mels)\n",
    "    return linear_scale_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating spectrograms\n",
      "max audio sample length: 17567\n",
      "Padding audio and compute mel and lin spectra..\n",
      "Processing text..\n",
      "Converting text to integers..\n",
      "Pad sequences to 7 ..\n",
      "I will take those for eval: [ 2 35  9  2  4]\n",
      "..and the remaining for train: [ 0  1  3  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 30 31 32 33 34 36 37 38 39 40 41 42 43 44 45 46 47 48 49] \n",
      "\n",
      "train data shape: (46, 80, 176) train label shape: (46, 1025, 176)\n",
      "eval data shape: (5, 80, 176) eval label shape: (5, 1025, 176) \n",
      "\n",
      "Populating traindata iterator\n",
      "Populating evaldata iterator\n"
     ]
    }
   ],
   "source": [
    "traindata_iterator, evaldata_iterator = get_iterators()\n",
    "linear_spectrogram = mx.sym.Variable('linear_spectrogram')\n",
    "mel_spectrogram = mx.sym.Variable('mel_spectrogram')\n",
    "\n",
    "net = mx.sym.MAERegressionOutput(data=postprocess(mel_spectrogram), label=linear_spectrogram)\n",
    "model = mx.mod.Module(symbol=net,\n",
    "                      context=ctx,\n",
    "                      data_names=['mel_spectrogram'],\n",
    "                      label_names=['linear_spectrogram']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "simple_bind error. Arguments:\nmel_spectrogram: (2, 80, 176)\nlinear_spectrogram: (2, 1025, 176)\nError in operator _plus11: [16:29:23] src/operator/nn/./../tensor/../elemwise_op_common.h:122: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node _plus11 at 1-th input: expected (2,80,1375), got (2,80,176)\n\nStack trace returned 10 entries:\n[bt] (0) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f5f135cfbbc]\n[bt] (1) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x293a73) [0x7f5f136e5a73]\n[bt] (2) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x294ab4) [0x7f5f136e6ab4]\n[bt] (3) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f5f1546a0ee]\n[bt] (4) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x201ac2c) [0x7f5f1546cc2c]\n[bt] (5) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1ffe5c9) [0x7f5f154505c9]\n[bt] (6) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1fff084) [0x7f5f15451084]\n[bt] (7) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2300) [0x7f5f153de6b0]\n[bt] (8) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f5f3958bec0]\n[bt] (9) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f5f3958b87d]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/symbol/symbol.py\u001b[0m in \u001b[0;36msimple_bind\u001b[0;34m(self, ctx, grad_req, type_dict, stype_dict, group2ctx, shared_arg_names, shared_exec, shared_buffer, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                                                  \u001b[0mshared_exec_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                                                  ctypes.byref(exe_handle)))\n\u001b[0m\u001b[1;32m   1486\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMXNetError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Error in operator _plus11: [16:29:23] src/operator/nn/./../tensor/../elemwise_op_common.h:122: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node _plus11 at 1-th input: expected (2,80,1375), got (2,80,176)\n\nStack trace returned 10 entries:\n[bt] (0) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f5f135cfbbc]\n[bt] (1) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x293a73) [0x7f5f136e5a73]\n[bt] (2) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x294ab4) [0x7f5f136e6ab4]\n[bt] (3) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f5f1546a0ee]\n[bt] (4) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x201ac2c) [0x7f5f1546cc2c]\n[bt] (5) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1ffe5c9) [0x7f5f154505c9]\n[bt] (6) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1fff084) [0x7f5f15451084]\n[bt] (7) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2300) [0x7f5f153de6b0]\n[bt] (8) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f5f3958bec0]\n[bt] (9) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f5f3958b87d]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bd94b0f8d64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0moptimizer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           num_epoch=8)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/module/base_module.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, optimizer, optimizer_params, eval_end_callback, eval_batch_end_callback, initializer, arg_params, aux_params, allow_missing, force_rebind, force_init, begin_epoch, num_epoch, validation_metric, monitor)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         self.bind(data_shapes=train_data.provide_data, label_shapes=train_data.provide_label,\n\u001b[0;32m--> 460\u001b[0;31m                   for_training=True, force_rebind=force_rebind)\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall_monitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/module/module.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module, grad_req)\u001b[0m\n\u001b[1;32m    415\u001b[0m                                                      \u001b[0mfixed_param_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fixed_param_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                                                      \u001b[0mgrad_req\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_req\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                                                      state_names=self._state_names)\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_exec_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_exec_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshared_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/module/executor_group.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, symbol, contexts, workload, data_shapes, label_shapes, param_names, for_training, inputs_need_grad, shared_group, logger, fixed_param_names, grad_req, state_names)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecide_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/module/executor_group.py\u001b[0m in \u001b[0;36mbind_exec\u001b[0;34m(self, data_shapes, label_shapes, shared_group, reshape)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 self.execs.append(self._bind_ith_exec(i, data_shapes_i, label_shapes_i,\n\u001b[0;32m--> 327\u001b[0;31m                                                       shared_group))\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/module/executor_group.py\u001b[0m in \u001b[0;36m_bind_ith_exec\u001b[0;34m(self, i, data_shapes, label_shapes, shared_group)\u001b[0m\n\u001b[1;32m    601\u001b[0m                                            \u001b[0mtype_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_arg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                                            \u001b[0mshared_exec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared_exec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                                            shared_buffer=shared_data_arrays, **input_shapes)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_exec_bytes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/symbol/symbol.py\u001b[0m in \u001b[0;36msimple_bind\u001b[0;34m(self, ctx, grad_req, type_dict, stype_dict, group2ctx, shared_arg_names, shared_exec, shared_buffer, **kwargs)\u001b[0m\n\u001b[1;32m   1489\u001b[0m                 \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"%s: %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;31m# update shared_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: simple_bind error. Arguments:\nmel_spectrogram: (2, 80, 176)\nlinear_spectrogram: (2, 1025, 176)\nError in operator _plus11: [16:29:23] src/operator/nn/./../tensor/../elemwise_op_common.h:122: Check failed: assign(&dattr, (*vec)[i]) Incompatible attr in node _plus11 at 1-th input: expected (2,80,1375), got (2,80,176)\n\nStack trace returned 10 entries:\n[bt] (0) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f5f135cfbbc]\n[bt] (1) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x293a73) [0x7f5f136e5a73]\n[bt] (2) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x294ab4) [0x7f5f136e6ab4]\n[bt] (3) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f5f1546a0ee]\n[bt] (4) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x201ac2c) [0x7f5f1546cc2c]\n[bt] (5) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1ffe5c9) [0x7f5f154505c9]\n[bt] (6) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1fff084) [0x7f5f15451084]\n[bt] (7) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2300) [0x7f5f153de6b0]\n[bt] (8) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f5f3958bec0]\n[bt] (9) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f5f3958b87d]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(traindata_iterator,\n",
    "          eval_data=evaldata_iterator,\n",
    "          optimizer=mx.optimizer.Adam,\n",
    "          optimizer_params={'learning_rate': 0.1, 'momentum': 0.9},\n",
    "          eval_metric='acc',\n",
    "          num_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_frames=mx.sym.zeros((1,80))\n",
    "full_frame=mx.sym.zeros((1,80))\n",
    "\n",
    "spectrograms_count=5 #dummy value\n",
    "for i in range(spectrograms_count):\n",
    "    predicted_frames,decoder_state = decoder(predicted_frames,decoder_state,reduction_factor)\n",
    "    full_frame=mx.sym.concat(full_frame,predicted_frames)\n",
    "\n",
    "spectral_magnitude=CBHG(full_frame, 8, emb_size, 80)\n",
    "\n",
    "graph=mx.viz.plot_network(\n",
    "    spectral_magnitude,\n",
    "    save_format='pdf',\n",
    "    title='decoder')\n",
    "#graph.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
