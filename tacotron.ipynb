{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TACOTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "from IPython.display import clear_output\n",
    "ctx= mx.cpu()\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import audio_process\n",
    "import traceback\n",
    "import subprocess\n",
    "import math\n",
    "from params import Hyperparams as hp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# command=\"ls train_data/*wav|while read i; do sox $i -n stat 2>&1|grep Leng|cut -d':'  -f 2|sed -r 's/\\s//g'; done|awk 'BEGIN{max_len=0}{if($0>max_len)max_len=$0}END{print max_len}'\"\n",
    "# max_len=subprocess.Popen(command, shell=True, stdout=subprocess.PIPE).stdout.read().strip()\n",
    "# max_audio_sec_len=math.ceil((float(max_len.decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating spectrograms\n",
      "max audio sample length: 17567\n",
      "Padding and compute spectrum\n",
      "Processing text..\n",
      "Converting text to integers..\n",
      "Get the length of the longest sequence..\n",
      "Pad sequences..\n",
      "diff [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15 16 17 18 19 20 21 22 23 25 26\n",
      " 27 28 29 30 31 32 34 35 36 37 38 39 40 41 42 43 44 45 46 47 49]\n",
      "random_eval_indxs [11 33 48 24 11]\n",
      "random_train_indxs [39 49 41  7 20]\n",
      "Split train and eval data\n",
      "[]\n",
      "Populating traindata iterator\n",
      "Populating evaldata iterator\n",
      "batch_size needs to be smaller than data size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-97-c687b7873cb6>\", line 148, in generate_train_eval_data\n",
      "    batch_size=batch_size)\n",
      "  File \"/home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/io.py\", line 648, in __init__\n",
      "    \"batch_size needs to be smaller than data size.\"\n",
      "AssertionError: batch_size needs to be smaller than data size.\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "[00:51:52] src/ndarray/ndarray.cc:102: Check failed: shape_[0] >= end (0 vs. 1) Slice end index out of range\n\nStack trace returned 10 entries:\n[bt] (0) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7fda6f5cfbbc]\n[bt] (1) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2174e77) [0x7fda715c6e77]\n[bt] (2) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x217ea95) [0x7fda715d0a95]\n[bt] (3) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXNDArraySlice+0x48) [0x7fda713d0918]\n[bt] (4) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fda95694ec0]\n[bt] (5) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fda9569487d]\n[bt] (6) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fda958a982e]\n[bt] (7) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12265) [0x7fda958aa265]\n[bt] (8) /home/stefano/anaconda3/envs/mxnet/bin/python(_PyObject_FastCallDict+0x8b) [0x7fda9c89a54b]\n[bt] (9) /home/stefano/anaconda3/envs/mxnet/bin/python(+0x19f00e) [0x7fda9c92d00e]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-c687b7873cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlongest_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m \u001b[0mgenerate_train_eval_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msound_files_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;31m# vocabulary = generate_vocabulary(texts_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-c687b7873cb6>\u001b[0m in \u001b[0;36mgenerate_train_eval_data\u001b[0;34m(text_trainset, sound_labels)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraindata_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/io.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miter_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/io.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             return DataBatch(data=self.getdata(), label=self.getlabel(), \\\n\u001b[0m\u001b[1;32m    686\u001b[0m                     pad=self.getpad(), index=None)\n\u001b[1;32m    687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/io.py\u001b[0m in \u001b[0;36mgetlabel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/io.py\u001b[0m in \u001b[0;36m_getdata\u001b[0;34m(self, data_source)\u001b[0m\n\u001b[1;32m    703\u001b[0m                         for i in sorted(self.idx[\n\u001b[1;32m    704\u001b[0m                             self.cursor:self.cursor + self.batch_size])\n\u001b[0;32m--> 705\u001b[0;31m                     ]]) for x in data_source\n\u001b[0m\u001b[1;32m    706\u001b[0m             ]\n\u001b[1;32m    707\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/io.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    703\u001b[0m                         for i in sorted(self.idx[\n\u001b[1;32m    704\u001b[0m                             self.cursor:self.cursor + self.batch_size])\n\u001b[0;32m--> 705\u001b[0;31m                     ]]) for x in data_source\n\u001b[0m\u001b[1;32m    706\u001b[0m             ]\n\u001b[1;32m    707\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NDArray only supports slicing with step size 1.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(self, start, stop)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         check_call(_LIB.MXNDArraySlice(\n\u001b[0;32m--> 656\u001b[0;31m             self.handle, start, stop, ctypes.byref(handle)))\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwritable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\"\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [00:51:52] src/ndarray/ndarray.cc:102: Check failed: shape_[0] >= end (0 vs. 1) Slice end index out of range\n\nStack trace returned 10 entries:\n[bt] (0) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7fda6f5cfbbc]\n[bt] (1) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2174e77) [0x7fda715c6e77]\n[bt] (2) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x217ea95) [0x7fda715d0a95]\n[bt] (3) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet/libmxnet.so(MXNDArraySlice+0x48) [0x7fda713d0918]\n[bt] (4) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fda95694ec0]\n[bt] (5) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fda9569487d]\n[bt] (6) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fda958a982e]\n[bt] (7) /home/stefano/anaconda3/envs/mxnet/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12265) [0x7fda958aa265]\n[bt] (8) /home/stefano/anaconda3/envs/mxnet/bin/python(_PyObject_FastCallDict+0x8b) [0x7fda9c89a54b]\n[bt] (9) /home/stefano/anaconda3/envs/mxnet/bin/python(+0x19f00e) [0x7fda9c92d00e]\n"
     ]
    }
   ],
   "source": [
    "num_hidden = 256\n",
    "reduction_factor=2\n",
    "emb_size=256\n",
    "batch_size=1\n",
    "\n",
    "\n",
    "def generate_vocabulary(texts_list):    \n",
    "    # get unique chars and put into a list\n",
    "    return list(set(''.join(texts_list)))\n",
    "    \n",
    "\n",
    "def generate_chars2numbers_mappings(vocabulary):\n",
    "    # create a chars <-> numbers mappings\n",
    "    char2index = {char:i for i,char in enumerate(vocabulary)}\n",
    "    index2char = {i:char for i,char in enumerate(vocabulary)}\n",
    "    \n",
    "    return char2index,index2char\n",
    "\n",
    "\n",
    "def text2numbers(texts_list,char2index_mapping):\n",
    "    numerical_texts=[]\n",
    "    for text in texts_list:\n",
    "        numerical_texts.append([char2index_mapping[char] for char in text])\n",
    "    return numerical_texts\n",
    "\n",
    "def open_data(input_file_path):\n",
    "      \n",
    "    texts, sound_files = [], []\n",
    "    \n",
    "    reader = csv.reader(codecs.open(input_file_path, 'rb', 'utf-8'))\n",
    "    for row in reader:\n",
    "        sound_filename, text = row\n",
    "        sound_file = \"train_data/\" + sound_filename + \".wav\"\n",
    "        text = re.sub(r\"[^ a-z']\", \"\", text.strip().lower())\n",
    "         \n",
    "        texts.append(text)\n",
    "        sound_files.append(sound_file)\n",
    "             \n",
    "    return texts, sound_files\n",
    "\n",
    "def generate_train_eval_data(text_trainset, sound_labels):\n",
    "    \n",
    "    assert len(sound_labels) == len(text_trainset)\n",
    "    \n",
    "    print(\"Generating spectrograms\")\n",
    "    \n",
    "    #tuples of wav and sr of that wav. wav is a 1D floats vector\n",
    "    wavs_srs = [audio_process.load_wave(sound_clip) for sound_clip in sound_labels]\n",
    "    longest_wav_sr = (max(wavs_srs, key= lambda wav: len(wav[0])))\n",
    "    #save the longest audio file length\n",
    "    max_samples_length=(len(longest_wav_sr[0]))\n",
    "    print(\"max audio sample length:\",max_samples_length)\n",
    "\n",
    "    spectra_lin = np.zeros((len(sound_labels),1+(hp.n_fft//2),math.ceil(max_samples_length/hp.hop_length)))\n",
    "    print(\"Padding and compute spectrum\")\n",
    "    for indx,wav_sr in enumerate(wavs_srs):\n",
    "        wav = wav_sr[0]\n",
    "        wav_length = len(wav)\n",
    "#         print(\"wav l\",w_length)\n",
    "        diff = max_samples_length-wav_length\n",
    "#         print(\"num of zeros to add\",diff)\n",
    "        padded = np.append(wav,np.zeros(diff))\n",
    "        spectrum_lin, spectrum_mel=(audio_process.do_spectrogram(y=padded,sr=hp.sr))\n",
    "#         print(padded_spectrum_lin.shape)\n",
    "        spectra_lin[indx,:,:]=spectrum_lin[:,:]\n",
    "    \n",
    "    print(\"Processing text..\")\n",
    "    vocabulary = generate_vocabulary(texts_list)\n",
    "    vocab_size=len(vocabulary)\n",
    "    char2index,index2char = generate_chars2numbers_mappings(vocabulary)\n",
    "\n",
    "    print(\"Converting text to integers..\")\n",
    "    texts_numerical = text2numbers(texts_list,char2index)\n",
    "#   /D E L E T E M E/ \n",
    "    texts_numerical[4]=np.concatenate((texts_numerical[4],[8,9]))\n",
    "#   /D E L E T E M E/\n",
    "\n",
    "    print(\"Get the length of the longest sequence..\")\n",
    "    longest_sequence = (max(texts_numerical, key= lambda seq: len(seq)))\n",
    "    longest_sequence_len=len(longest_sequence)\n",
    "    print(\"Pad sequences..\")\n",
    "    \n",
    "    def _padseq(seq,max_len):\n",
    "        diff=max_len-len(seq)\n",
    "        if diff>0: #SHITTY USELESS MXNET API. CANNOT CONCAT A NON-EMPTY WITH EMPTY ARRAY. EDIT: use numpy now. Still using this condition\n",
    "            pad = np.zeros(diff)-1\n",
    "            seq=np.append(seq,[pad])\n",
    "        return seq\n",
    "    \n",
    "    padded_sequences = mx.nd.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda seq: _padseq(seq,longest_sequence_len), texts_numerical\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "        \n",
    "    \n",
    "    texts_one_hot=mx.ndarray.one_hot(padded_sequences,vocab_size)\n",
    "    train_data = mx.ndarray.take(texts_one_hot,mx.nd.array([0,1]))\n",
    "    train_label = []\n",
    "    eval_data = []\n",
    "    eval_label = []\n",
    " \n",
    "    \n",
    "    # get 10% of dataset as eval data\n",
    "    random_eval_indxs = (np.random.randint(0, high=len(sound_labels), size=len(sound_labels)//10))\n",
    "    all_indxs = np.arange(50)\n",
    "    diff = np.setdiff1d(all_indxs,random_eval_indxs)\n",
    "    print(\"diff\",diff)\n",
    "    \n",
    "    random_train_indxs = len(sound_labels)-(np.random.randint(0,high=len(sound_labels),size=len(sound_labels)//10))\n",
    "    print(\"random_eval_indxs\",random_eval_indxs)\n",
    "    print(\"random_train_indxs\",random_train_indxs)\n",
    "    \n",
    "#     for i in range(size//10):\n",
    "#         if i%10 == 0:\n",
    "#             print(\"Processed %d samples\" % i)\n",
    "#         try:\n",
    "#             if i in random_samples:\n",
    "#                 eval_data=mx.ndarray.concat(eval_data,texts_one_hot[i])\n",
    "#                 eval_label.append(spectra_lin[i])\n",
    "#             else:\n",
    "#                 train_data.append(texts_one_hot[i])\n",
    "#                 train_label.append(spectra_lin[i])\n",
    "                \n",
    "#         except IndexError as e:\n",
    "#             print(e)\n",
    "#             print(\"i=%s, thing to add: %s %s\"%(i,texts_one_hot[i],sound_labels[i]))\n",
    "\n",
    "    print(\"Split train and eval data\")\n",
    "    print(eval_data)\n",
    "\n",
    "    train_data = mx.nd.array(train_data)\n",
    "    train_label = mx.nd.array(train_label)\n",
    "    eval_data = mx.nd.array(eval_data)\n",
    "    eval_label = mx.nd.array(eval_label)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        print(\"Populating traindata iterator\")\n",
    "        traindata_iterator = mx.io.NDArrayIter(data={'mel_spectrogram':train_data},\n",
    "                                label={'linear_spectrogram':train_label},\n",
    "                                batch_size=batch_size)\n",
    "        print(\"Populating evaldata iterator\")\n",
    "        evaldata_iterator = mx.io.NDArrayIter(data={'mel_spectrogram':eval_data},\n",
    "                                label={'linear_spectrogram':eval_label},\n",
    "                                batch_size=batch_size)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    \n",
    "    for batch in traindata_iterator:\n",
    "        print(batch.data[0].asnumpy())\n",
    "        print(batch.data[0].shape)\n",
    "\n",
    "    #return traindata_iterator, evaldata_iterator\n",
    "\n",
    "\n",
    "texts_list, sound_files_list = open_data('train_data/dataset.csv')\n",
    "size=len(sound_files_list)\n",
    "\n",
    "longest_word = 0\n",
    "for text in texts_list:\n",
    "    longest_word = max(longest_word,len(text))\n",
    "generate_train_eval_data(texts_list, sound_files_list)\n",
    "\n",
    "# vocabulary = generate_vocabulary(texts_list)\n",
    "# vocab_size=len(vocabulary)\n",
    "# char2index,index2char = generate_chars2numbers_mappings(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FC-256-ReLU → Dropout(0.5) → FC-128-ReLU → Dropout(0.5)\n",
    "\"\"\"\n",
    "def prenet_pass(data):\n",
    "    fc1 = mx.symbol.FullyConnected(data=data, num_hidden=emb_size, name='prenet_fc1')\n",
    "    act1 = mx.symbol.Activation(data=fc1, act_type='relu', name='prenet_act1')\n",
    "    drop1 = mx.symbol.Dropout(act1, p=0.5, name='prenet_drop1')\n",
    "    \n",
    "    fc2 = mx.symbol.FullyConnected(data=drop1, num_hidden=emb_size//2, name='prenet_fc2')\n",
    "    act2 = mx.symbol.Activation(data=fc2, act_type='relu', name='prenet_act2')\n",
    "    prenet_output = mx.symbol.Dropout(act2, p=0.5, name='prenet_drop2')\n",
    "    \n",
    "    return prenet_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# banco di filtri convolutivi. Vengono creati K filtri con kernel 1D di dimensione:k \n",
    "def conv1dBank(conv_input, K):\n",
    "    conv=mx.sym.Convolution(data=conv_input, kernel=(1,1), num_filter=emb_size//2)\n",
    "    (conv, mean, var) = mx.sym.BatchNorm(data=conv, output_mean_var=True)\n",
    "    conv = mx.sym.Activation(data=conv, act_type='relu')\n",
    "    for k in range(2, K+1):\n",
    "        convi = mx.sym.Convolution(data=conv_input, kernel=(k,1), num_filter=emb_size//2)\n",
    "        (convi, mean, var) = mx.sym.BatchNorm(data=convi, output_mean_var=True)\n",
    "        convi = mx.sym.Activation(data=convi, act_type='relu')\n",
    "        conv = mx.symbol.concat(conv,convi)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# highway\n",
    "def highway_layer(data):\n",
    "    H= mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=data, num_hidden=emb_size//2, name=\"highway_fcH\"),\n",
    "        act_type=\"relu\"\n",
    "    )\n",
    "    T= mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=data, num_hidden=emb_size//2, bias=mx.sym.Variable('bias'), name=\"highway_fcT\"),\n",
    "        act_type=\"sigmoid\"\n",
    "    )\n",
    "    return  H * T + data * (1.0 - T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CBHG\n",
    "def CBHG(data,K,proj1_size,proj2_size):\n",
    "    #se si usa infer_shape su convbank dando la dimensione dell'input, viene dedotta la shape appunto \n",
    "    bank = conv1dBank(data,K)\n",
    "    poold_bank = mx.sym.Pooling(data=bank, pool_type='max', kernel=(2, 1), stride=(1,1), name=\"CBHG_pool\")\n",
    "\n",
    "    proj1 = mx.sym.Convolution(data=poold_bank, kernel=(3,1), num_filter=proj1_size, name='CBHG_conv1')\n",
    "    (proj1, proj1_mean, proj1_var) = mx.sym.BatchNorm(data=proj1, output_mean_var=True, name='CBHG_batch1')\n",
    "    proj1 = mx.sym.Activation(data=proj1, act_type='relu', name='CBHG_act1')\n",
    "\n",
    "    proj2 = mx.sym.Convolution(proj1, kernel=(3,1), num_filter=proj2_size, name='CBHG_conv2')\n",
    "    (proj2, proj2_mean, proj2_var) = mx.sym.BatchNorm(data=proj2, output_mean_var=True, name='CBHG_batch2')\n",
    "    \n",
    "    residual= proj2 + data\n",
    "\n",
    "    for i in range(4):\n",
    "        residual = highway_layer(residual)\n",
    "    highway_pass = residual\n",
    "   \n",
    "    bidirectional_gru_cell = mx.rnn.BidirectionalCell(\n",
    "        mx.rnn.GRUCell(num_hidden=emb_size//2, prefix='CBHG_gru1'),\n",
    "        mx.rnn.GRUCell(num_hidden=emb_size//2, prefix='CBHG_gru2'),\n",
    "        output_prefix='CBHG_bi_'\n",
    "    )\n",
    "    outputs, states = bidirectional_gru_cell.unroll(1, inputs=highway_pass, merge_outputs=True)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "def encoder(data):\n",
    "    embed_vector = mx.sym.Embedding(data=data, input_dim=longest_word, output_dim=emb_size, name='encoder_embed')\n",
    "    prenet_output = prenet_pass(embed_vector)\n",
    "    return CBHG(prenet_output,16, emb_size//2, emb_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = mx.sym.Variable('text')\n",
    "\n",
    "encoded = encoder(text)\n",
    "graph=mx.viz.plot_network(\n",
    "    encoded,\n",
    "    save_format='pdf',\n",
    "    title='encoder')\n",
    "#graph.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoder\n",
    "def decoder(input_spectrogram,context,reduction_factor):\n",
    "    #embed_vector = mx.sym.Embedding(data=input_spectrogram, input_dim=80, output_dim=emb_size, name='decoder_embed')\n",
    "    prenet_output = prenet_pass(input_spectrogram)\n",
    "        \n",
    "    stack = mx.rnn.SequentialRNNCell()\n",
    "    stack.add(mx.rnn.GRUCell(num_hidden=emb_size,prefix='decoder_layer1_'))\n",
    "    stack.add(mx.rnn.GRUCell(num_hidden=emb_size,prefix='decoder_layer2_'))\n",
    "    \n",
    "    residual_gru_stack = mx.rnn.ResidualCell(stack)\n",
    "    \n",
    "    gru_outputs,states = residual_gru_stack.unroll(length=1,\n",
    "                                               inputs=prenet_output,\n",
    "                                               begin_state=context,\n",
    "                                               merge_outputs=True)\n",
    "\n",
    "    predicted_frames = mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=gru_outputs, num_hidden=80*reduction_factor),\n",
    "        act_type=\"relu\"\n",
    "    )\n",
    "    \n",
    "    return predicted_frames, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postprocess(input_mel_spectgrograms):\n",
    "    linear_scale_spectrograms=CBHG(input_mel_spectgrograms,8,emb_size,80)\n",
    "    return linear_scale_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_spectrogram = mx.sym.Variable('linear_spectrogram')\n",
    "\n",
    "spectrograms_count=5 #dummy value\n",
    "decoder_state=[encoded,encoded]\n",
    "predicted_frames=mx.sym.zeros((1,80))\n",
    "full_frame=mx.sym.zeros((1,80))\n",
    "mel_spectrogram = mx.sym.Variable('mel_spectrogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = mx.sym.MAERegressionOutput(data=postprocess(mel_spectrogram), label=linear_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = mx.mod.Module(symbol=net,\n",
    "                      context=ctx,\n",
    "                      data_names=['mel_spectrogram'],\n",
    "                      label_names=['linear_spectrogram']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data provided by data_shapes don't match names specified by data_names ([DataDesc[_0_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_1_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_2_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_3_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_4_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_5_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_6_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_7_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_8_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_9_data,(2, 4),<class 'numpy.float32'>,NCHW]] vs. ['mel_spectrogram'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c80217d66369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0moptimizer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           num_epoch=8)\n\u001b[0m",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/base_module.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, optimizer, optimizer_params, eval_end_callback, eval_batch_end_callback, initializer, arg_params, aux_params, allow_missing, force_rebind, force_init, begin_epoch, num_epoch, validation_metric, monitor)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         self.bind(data_shapes=train_data.provide_data, label_shapes=train_data.provide_label,\n\u001b[0;32m--> 460\u001b[0;31m                   for_training=True, force_rebind=force_rebind)\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall_monitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/module.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module, grad_req)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         self._data_shapes, self._label_shapes = _parse_data_desc(\n\u001b[0;32m--> 400\u001b[0;31m             self.data_names, self.label_names, data_shapes, label_shapes)\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshared_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/base_module.py\u001b[0m in \u001b[0;36m_parse_data_desc\u001b[0;34m(data_names, label_names, data_shapes, label_shapes)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;34m\"\"\"parse data_attrs into DataDesc format and check that names match\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdata_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataDesc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDataDesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0m_check_names_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel_shapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mlabel_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataDesc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDataDesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/base_module.py\u001b[0m in \u001b[0;36m_check_names_match\u001b[0;34m(data_names, data_shapes, name, throw)\u001b[0m\n\u001b[1;32m     61\u001b[0m             name, name, str(data_shapes), str(data_names))\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data provided by data_shapes don't match names specified by data_names ([DataDesc[_0_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_1_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_2_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_3_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_4_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_5_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_6_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_7_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_8_data,(2, 4),<class 'numpy.float32'>,NCHW], DataDesc[_9_data,(2, 4),<class 'numpy.float32'>,NCHW]] vs. ['mel_spectrogram'])"
     ]
    }
   ],
   "source": [
    "model.fit(traindata_iterator,\n",
    "          eval_data=evaldata_iterator,\n",
    "          optimizer=mx.optimizer.Adam,\n",
    "          optimizer_params={'learning_rate': 0.1, 'momentum': 0.9},\n",
    "          eval_metric='acc',\n",
    "          num_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(spectrograms_count):\n",
    "    predicted_frames,decoder_state = decoder(predicted_frames,decoder_state,reduction_factor)\n",
    "    full_frame=mx.sym.concat(full_frame,predicted_frames)\n",
    "\n",
    "spectral_magnitude=CBHG(full_frame, 8, emb_size, 80)\n",
    "\n",
    "graph=mx.viz.plot_network(\n",
    "    spectral_magnitude,\n",
    "    save_format='pdf',\n",
    "    title='decoder')\n",
    "#graph.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
