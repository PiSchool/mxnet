{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TACOTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "from IPython.display import clear_output\n",
    "ctx= mx.cpu()\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import audio_process\n",
    "import traceback\n",
    "import subprocess\n",
    "import math\n",
    "from params import Hyperparams as hp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# command=\"ls train_data/*wav|while read i; do sox $i -n stat 2>&1|grep Leng|cut -d':'  -f 2|sed -r 's/\\s//g'; done|awk 'BEGIN{max_len=0}{if($0>max_len)max_len=$0}END{print max_len}'\"\n",
    "# max_len=subprocess.Popen(command, shell=True, stdout=subprocess.PIPE).stdout.read().strip()\n",
    "# max_audio_sec_len=math.ceil((float(max_len.decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_hidden = 256\n",
    "reduction_factor=2\n",
    "emb_size=256\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "def generate_vocabulary(texts_list):    \n",
    "    # get unique chars and put into a list\n",
    "    return list(set(''.join(texts_list)))\n",
    "    \n",
    "\n",
    "def generate_chars2numbers_mappings(vocabulary):\n",
    "    # create a chars <-> numbers mappings\n",
    "    char2index = {char:i for i,char in enumerate(vocabulary)}\n",
    "    index2char = {i:char for i,char in enumerate(vocabulary)}\n",
    "    \n",
    "    return char2index,index2char\n",
    "\n",
    "\n",
    "def text2numbers(texts_list,char2index_mapping):\n",
    "    numerical_texts=[]\n",
    "    for text in texts_list:\n",
    "        numerical_texts.append([char2index_mapping[char] for char in text])\n",
    "    return numerical_texts\n",
    "\n",
    "def open_data(input_file_path):\n",
    "      \n",
    "    texts, sound_files = [], []\n",
    "    \n",
    "    reader = csv.reader(codecs.open(input_file_path, 'rb', 'utf-8'))\n",
    "    for row in reader:\n",
    "        sound_filename, text = row\n",
    "        sound_file = \"train_data/\" + sound_filename + \".wav\"\n",
    "        text = re.sub(r\"[^ a-z']\", \"\", text.strip().lower())\n",
    "         \n",
    "        texts.append(text)\n",
    "        sound_files.append(sound_file)\n",
    "             \n",
    "    return texts, sound_files\n",
    "# Returns: one-hot-encoded-text, linear spectrum, mel spectrum\n",
    "# Shapes: (data_length, ?, ?), (data_length, (n_fft/2)+1, ceil(max_audio_length))\n",
    "def generate_text_spectra(text_trainset, sound_labels):\n",
    "    \n",
    "    assert len(sound_labels) == len(text_trainset)\n",
    "    \n",
    "    print(\"Generating spectrograms\")\n",
    "    \n",
    "    #tuples of wav and sr of that wav. wav is a 1D floats vector\n",
    "    wavs_srs = [audio_process.load_wave(sound_clip) for sound_clip in sound_labels]\n",
    "    longest_wav_sr = (max(wavs_srs, key= lambda wav: len(wav[0])))\n",
    "    #save the longest audio file length\n",
    "    max_samples_length=(len(longest_wav_sr[0]))\n",
    "    print(\"max audio sample length:\",max_samples_length)\n",
    "\n",
    "    #prepare the data structure for save all the spectra\n",
    "    spectra_lin = mx.ndarray.zeros((len(sound_labels),1+(hp.n_fft//2),math.ceil(max_samples_length/hp.hop_length)))\n",
    "    spectra_mel = mx.ndarray.zeros((len(sound_labels),hp.n_mels,math.ceil(max_samples_length/hp.hop_length)))\n",
    "    print(\"Padding audio and compute mel and lin spectra..\")\n",
    "    for indx,wav_sr in enumerate(wavs_srs):\n",
    "        wav = wav_sr[0]\n",
    "        wav_length = len(wav)\n",
    "#         print(\"wav l\",w_length)\n",
    "        diff = max_samples_length-wav_length\n",
    "#         print(\"num of zeros to add\",diff)\n",
    "        padded = np.append(wav,np.zeros(diff))\n",
    "        # get the spectrum from the padded sound\n",
    "        spectrum_lin, spectrum_mel=(audio_process.do_spectrogram(y=padded,sr=hp.sr))\n",
    "#         print(padded_spectrum_lin.shape)\n",
    "        # save into the ndarray\n",
    "        spectra_lin[indx,:,:]=spectrum_lin[:,:]\n",
    "        spectra_mel[indx,:,:]=spectrum_mel[:,:]\n",
    "    \n",
    "    \n",
    "    print(\"Processing text..\")\n",
    "    vocabulary = generate_vocabulary(text_trainset)\n",
    "    vocab_size=len(vocabulary)\n",
    "    char2index,index2char = generate_chars2numbers_mappings(vocabulary)\n",
    "\n",
    "    print(\"Converting text to integers..\")\n",
    "    texts_numerical = text2numbers(text_trainset,char2index)\n",
    "    # simulate a different sequence length\n",
    "#   /D E L E T E M E/ \n",
    "    texts_numerical[4]=np.concatenate((texts_numerical[4],[8,9]))\n",
    "#   /D E L E T E M E/\n",
    "\n",
    "    longest_sequence = (max(texts_numerical, key= lambda seq: len(seq)))\n",
    "    longest_sequence_len=len(longest_sequence)\n",
    "    print(\"Pad sequences to\",longest_sequence_len,\"..\")\n",
    "    # helper function for the lambda expression\n",
    "    def _padseq(seq,max_len):\n",
    "        diff=max_len-len(seq)\n",
    "        if diff>0: \n",
    "            # SHITTY USELESS MXNET API. CANNOT CONCAT A NON-EMPTY WITH EMPTY ARRAY. \n",
    "            # EDIT: use numpy now. Still using this condition for safety\n",
    "            pad = np.zeros(diff)-1\n",
    "            seq=np.append(seq,[pad])\n",
    "        return seq\n",
    "    \n",
    "    padded_sequences = mx.nd.array(\n",
    "        list(\n",
    "            map(\n",
    "                lambda seq: _padseq(seq,longest_sequence_len), texts_numerical\n",
    "            )\n",
    "        )\n",
    "    )   \n",
    "    \n",
    "    texts_one_hot=mx.ndarray.one_hot(padded_sequences,vocab_size)\n",
    "    \n",
    "    return texts_one_hot, spectra_lin, spectra_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterators(data='train_data/dataset.csv'):\n",
    "    texts_list, sound_files_list = open_data(data)\n",
    "    size=len(sound_files_list)\n",
    "\n",
    "    texts_one_hot, spectra_lin, spectra_mel = generate_text_spectra(texts_list, sound_files_list)\n",
    "\n",
    "    # get 10% of dataset as eval data \n",
    "    eval_indxs = list(set(np.random.randint(0, high=size, size=size//10)))\n",
    "    # remaining indexes for the train\n",
    "    train_indxs = np.setdiff1d(np.arange(size),eval_indxs)\n",
    "\n",
    "    print(\"I will take those for eval:\",eval_indxs)\n",
    "    print(\"..and the remaining for train:\",train_indxs,\"\\n\")\n",
    "\n",
    "    #take from the array (1st arg) the indexes of the first dimension specified by the 2nd arg\n",
    "    #train_txt take the one_hot matrices\n",
    "    train_txt_data = mx.ndarray.take(texts_one_hot,mx.nd.array(train_indxs))\n",
    "    eval_txt_data = mx.ndarray.take(texts_one_hot,mx.nd.array(eval_indxs))\n",
    "\n",
    "    train_data = mx.ndarray.take(spectra_mel,mx.nd.array(train_indxs))\n",
    "    train_label = mx.ndarray.take(spectra_lin,mx.nd.array(train_indxs))\n",
    "\n",
    "    eval_data = mx.ndarray.take(spectra_mel,mx.nd.array(eval_indxs))\n",
    "    eval_label = mx.ndarray.take(spectra_lin,mx.nd.array(eval_indxs))\n",
    "\n",
    "    print(\"train data shape:\",train_data.shape,\"train label shape:\",train_label.shape)\n",
    "    print(\"eval data shape:\", eval_data.shape,\"eval label shape:\",eval_label.shape,\"\\n\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(\"Populating traindata iterator\")\n",
    "        traindata_iterator = mx.io.NDArrayIter(data={'mel_spectrogram':train_data},\n",
    "                                label={'linear_spectrogram':train_label},\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True)\n",
    "        print(\"Populating evaldata iterator\")\n",
    "        evaldata_iterator = mx.io.NDArrayIter(data={'mel_spectrogram':eval_data},\n",
    "                                label={'linear_spectrogram':eval_label},\n",
    "                                batch_size=batch_size)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "#     for batch in traindata_iterator:\n",
    "#         print(batch.data[0].asnumpy())\n",
    "#         print(batch.data[0].shape)\n",
    "    \n",
    "    return traindata_iterator,evaldata_iterator\n",
    "\n",
    "#print(get_iterators())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FC-256-ReLU → Dropout(0.5) → FC-128-ReLU → Dropout(0.5)\n",
    "\"\"\"\n",
    "def prenet_pass(data):\n",
    "    fc1 = mx.symbol.FullyConnected(data=data, num_hidden=emb_size, name='prenet_fc1')\n",
    "    act1 = mx.symbol.Activation(data=fc1, act_type='relu', name='prenet_act1')\n",
    "    drop1 = mx.symbol.Dropout(act1, p=0.5, name='prenet_drop1')\n",
    "    \n",
    "    fc2 = mx.symbol.FullyConnected(data=drop1, num_hidden=emb_size//2, name='prenet_fc2')\n",
    "    act2 = mx.symbol.Activation(data=fc2, act_type='relu', name='prenet_act2')\n",
    "    prenet_output = mx.symbol.Dropout(act2, p=0.5, name='prenet_drop2')\n",
    "    \n",
    "    return prenet_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# banco di filtri convolutivi. Vengono creati K filtri con kernel 1D di dimensione:k \n",
    "def conv1dBank(conv_input, K):\n",
    "    conv=mx.sym.Convolution(data=conv_input, kernel=(1,1), num_filter=emb_size//2)\n",
    "    (conv, mean, var) = mx.sym.BatchNorm(data=conv, output_mean_var=True)\n",
    "    conv = mx.sym.Activation(data=conv, act_type='relu')\n",
    "    for k in range(2, K+1):\n",
    "        convi = mx.sym.Convolution(data=conv_input, kernel=(k,1), num_filter=emb_size//2)\n",
    "        (convi, mean, var) = mx.sym.BatchNorm(data=convi, output_mean_var=True)\n",
    "        convi = mx.sym.Activation(data=convi, act_type='relu')\n",
    "        conv = mx.symbol.concat(conv,convi)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highway\n",
    "def highway_layer(data):\n",
    "    H= mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=data, num_hidden=emb_size//2, name=\"highway_fcH\"),\n",
    "        act_type=\"relu\"\n",
    "    )\n",
    "    T= mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=data, num_hidden=emb_size//2, bias=mx.sym.Variable('bias'), name=\"highway_fcT\"),\n",
    "        act_type=\"sigmoid\"\n",
    "    )\n",
    "    return  H * T + data * (1.0 - T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CBHG\n",
    "def CBHG(data,K,proj1_size,proj2_size):\n",
    "    #se si usa infer_shape su convbank dando la dimensione dell'input, viene dedotta la shape appunto \n",
    "    bank = conv1dBank(data,K)\n",
    "    poold_bank = mx.sym.Pooling(data=bank, pool_type='max', kernel=(2, 1), stride=(1,1), name=\"CBHG_pool\")\n",
    "\n",
    "    proj1 = mx.sym.Convolution(data=poold_bank, kernel=(3,1), num_filter=proj1_size, name='CBHG_conv1')\n",
    "    (proj1, proj1_mean, proj1_var) = mx.sym.BatchNorm(data=proj1, output_mean_var=True, name='CBHG_batch1')\n",
    "    proj1 = mx.sym.Activation(data=proj1, act_type='relu', name='CBHG_act1')\n",
    "\n",
    "    proj2 = mx.sym.Convolution(proj1, kernel=(3,1), num_filter=proj2_size, name='CBHG_conv2')\n",
    "    (proj2, proj2_mean, proj2_var) = mx.sym.BatchNorm(data=proj2, output_mean_var=True, name='CBHG_batch2')\n",
    "    \n",
    "    residual= proj2 + data\n",
    "\n",
    "    for i in range(4):\n",
    "        residual = highway_layer(residual)\n",
    "    highway_pass = residual\n",
    "   \n",
    "    bidirectional_gru_cell = mx.rnn.BidirectionalCell(\n",
    "        mx.rnn.GRUCell(num_hidden=emb_size//2, prefix='CBHG_gru1'),\n",
    "        mx.rnn.GRUCell(num_hidden=emb_size//2, prefix='CBHG_gru2'),\n",
    "        output_prefix='CBHG_bi_'\n",
    "    )\n",
    "    outputs, states = bidirectional_gru_cell.unroll(1, inputs=highway_pass, merge_outputs=True)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "def encoder(data):\n",
    "    embed_vector = mx.sym.Embedding(data=data, input_dim=longest_word, output_dim=emb_size, name='encoder_embed')\n",
    "    prenet_output = prenet_pass(embed_vector)\n",
    "    return CBHG(prenet_output,16, emb_size//2, emb_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = mx.sym.Variable('text')\n",
    "\n",
    "#encoded = encoder(text)\n",
    "#graph=mx.viz.plot_network(\n",
    "#    encoded,\n",
    "#    save_format='pdf',\n",
    "#    title='encoder')\n",
    "#graph.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "def decoder(input_spectrogram,context,reduction_factor):\n",
    "    #embed_vector = mx.sym.Embedding(data=input_spectrogram, input_dim=80, output_dim=emb_size, name='decoder_embed')\n",
    "    prenet_output = prenet_pass(input_spectrogram)\n",
    "        \n",
    "    stack = mx.rnn.SequentialRNNCell()\n",
    "    stack.add(mx.rnn.GRUCell(num_hidden=emb_size,prefix='decoder_layer1_'))\n",
    "    stack.add(mx.rnn.GRUCell(num_hidden=emb_size,prefix='decoder_layer2_'))\n",
    "    \n",
    "    residual_gru_stack = mx.rnn.ResidualCell(stack)\n",
    "    \n",
    "    gru_outputs,states = residual_gru_stack.unroll(length=1,\n",
    "                                               inputs=prenet_output,\n",
    "                                               begin_state=context,\n",
    "                                               merge_outputs=True)\n",
    "\n",
    "    predicted_frames = mx.symbol.Activation(\n",
    "        data=mx.symbol.FullyConnected(data=gru_outputs, num_hidden=80*reduction_factor),\n",
    "        act_type=\"relu\"\n",
    "    )\n",
    "    \n",
    "    return predicted_frames, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(input_mel_spectgrograms):\n",
    "    linear_scale_spectrograms=CBHG(input_mel_spectgrograms,8,emb_size,80)\n",
    "    return linear_scale_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_spectrogram = mx.sym.Variable('linear_spectrogram')\n",
    "\n",
    "#spectrograms_count=5 #dummy value\n",
    "#decoder_state=[encoded,encoded]\n",
    "#predicted_frames=mx.sym.zeros((1,80))\n",
    "full_frame=mx.sym.zeros((1,80))\n",
    "mel_spectrogram = mx.sym.Variable('mel_spectrogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mx.sym.MAERegressionOutput(data=postprocess(mel_spectrogram), label=linear_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mx.mod.Module(symbol=net,\n",
    "                      context=ctx,\n",
    "                      data_names=['mel_spectrogram'],\n",
    "                      label_names=['linear_spectrogram']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating spectrograms\n",
      "max audio sample length: 23999\n",
      "Padding audio and compute mel and lin spectra..\n",
      "Processing text..\n",
      "Converting text to integers..\n",
      "Pad sequences to 7 ..\n",
      "I will take those for eval: [33, 130, 35, 36, 100, 198, 39, 40, 41, 11, 172, 75, 109, 145, 182, 86, 120, 124, 61]\n",
      "..and the remaining for train: [  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  34  37  38  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  62  63  64  65  66  67  68  69  70  71  72  73  74  76  77  78  79  80\n",
      "  81  82  83  84  85  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 101 102 103 104 105 106 107 108 110 111 112 113 114 115 116 117 118 119\n",
      " 121 122 123 125 126 127 128 129 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 146 147 148 149 150 151 152 153 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 171 173 174 175 176 177 178\n",
      " 179 180 181 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 199] \n",
      "\n",
      "train data shape: (181, 80, 240) train label shape: (181, 1025, 240)\n",
      "eval data shape: (19, 80, 240) eval label shape: (19, 1025, 240) \n",
      "\n",
      "Populating traindata iterator\n",
      "Populating evaldata iterator\n"
     ]
    }
   ],
   "source": [
    "traindata_iterator, evaldata_iterator = get_iterators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch: data shapes: [(10, 80, 240)] label shapes: [(10, 1025, 240)]\n"
     ]
    }
   ],
   "source": [
    "item = traindata_iterator.next()\n",
    "print(item)\n",
    "traindata_iterator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "simple_bind error. Arguments:\nmel_spectrogram: (1, 80, 240)\nlinear_spectrogram: (1, 1025, 240)\nError in operator convolution0: [14:35:36] src/operator/./convolution-inl.h:491: Check failed: dshp.ndim() == 4U (3 vs. 4) Input data should be 4D in batch-num_filter-y-x\n\nStack trace returned 10 entries:\n[bt] (0) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f3d2d685bbc]\n[bt] (1) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2299e00) [0x7f3d2f7a1e00]\n[bt] (2) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x21f67b7) [0x7f3d2f6fe7b7]\n[bt] (3) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f3d2f5200ee]\n[bt] (4) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x201abc1) [0x7f3d2f522bc1]\n[bt] (5) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x1ffe5c9) [0x7f3d2f5065c9]\n[bt] (6) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x1fff084) [0x7f3d2f507084]\n[bt] (7) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2300) [0x7f3d2f4946b0]\n[bt] (8) /home/ai_ja_nai/pischool/mxnet/venv3/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7f3d5c2d0e20]\n[bt] (9) /home/ai_ja_nai/pischool/mxnet/venv3/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7f3d5c2d088b]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/symbol/symbol.py\u001b[0m in \u001b[0;36msimple_bind\u001b[0;34m(self, ctx, grad_req, type_dict, stype_dict, group2ctx, shared_arg_names, shared_exec, shared_buffer, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                                                  \u001b[0mshared_exec_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                                                  ctypes.byref(exe_handle)))\n\u001b[0m\u001b[1;32m   1486\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMXNetError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Error in operator convolution0: [14:35:36] src/operator/./convolution-inl.h:491: Check failed: dshp.ndim() == 4U (3 vs. 4) Input data should be 4D in batch-num_filter-y-x\n\nStack trace returned 10 entries:\n[bt] (0) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f3d2d685bbc]\n[bt] (1) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2299e00) [0x7f3d2f7a1e00]\n[bt] (2) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x21f67b7) [0x7f3d2f6fe7b7]\n[bt] (3) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f3d2f5200ee]\n[bt] (4) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x201abc1) [0x7f3d2f522bc1]\n[bt] (5) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x1ffe5c9) [0x7f3d2f5065c9]\n[bt] (6) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x1fff084) [0x7f3d2f507084]\n[bt] (7) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2300) [0x7f3d2f4946b0]\n[bt] (8) /home/ai_ja_nai/pischool/mxnet/venv3/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7f3d5c2d0e20]\n[bt] (9) /home/ai_ja_nai/pischool/mxnet/venv3/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7f3d5c2d088b]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c80217d66369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0moptimizer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           num_epoch=8)\n\u001b[0m",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/base_module.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, optimizer, optimizer_params, eval_end_callback, eval_batch_end_callback, initializer, arg_params, aux_params, allow_missing, force_rebind, force_init, begin_epoch, num_epoch, validation_metric, monitor)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         self.bind(data_shapes=train_data.provide_data, label_shapes=train_data.provide_label,\n\u001b[0;32m--> 460\u001b[0;31m                   for_training=True, force_rebind=force_rebind)\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall_monitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/module.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, data_shapes, label_shapes, for_training, inputs_need_grad, force_rebind, shared_module, grad_req)\u001b[0m\n\u001b[1;32m    415\u001b[0m                                                      \u001b[0mfixed_param_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fixed_param_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                                                      \u001b[0mgrad_req\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_req\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                                                      state_names=self._state_names)\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_exec_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_exec_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshared_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/executor_group.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, symbol, contexts, workload, data_shapes, label_shapes, param_names, for_training, inputs_need_grad, shared_group, logger, fixed_param_names, grad_req, state_names)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecide_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/executor_group.py\u001b[0m in \u001b[0;36mbind_exec\u001b[0;34m(self, data_shapes, label_shapes, shared_group, reshape)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 self.execs.append(self._bind_ith_exec(i, data_shapes_i, label_shapes_i,\n\u001b[0;32m--> 327\u001b[0;31m                                                       shared_group))\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/module/executor_group.py\u001b[0m in \u001b[0;36m_bind_ith_exec\u001b[0;34m(self, i, data_shapes, label_shapes, shared_group)\u001b[0m\n\u001b[1;32m    601\u001b[0m                                            \u001b[0mtype_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_arg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                                            \u001b[0mshared_exec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared_exec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                                            shared_buffer=shared_data_arrays, **input_shapes)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_exec_bytes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/symbol/symbol.py\u001b[0m in \u001b[0;36msimple_bind\u001b[0;34m(self, ctx, grad_req, type_dict, stype_dict, group2ctx, shared_arg_names, shared_exec, shared_buffer, **kwargs)\u001b[0m\n\u001b[1;32m   1489\u001b[0m                 \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"%s: %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m         \u001b[0;31m# update shared_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: simple_bind error. Arguments:\nmel_spectrogram: (1, 80, 240)\nlinear_spectrogram: (1, 1025, 240)\nError in operator convolution0: [14:35:36] src/operator/./convolution-inl.h:491: Check failed: dshp.ndim() == 4U (3 vs. 4) Input data should be 4D in batch-num_filter-y-x\n\nStack trace returned 10 entries:\n[bt] (0) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x17dbbc) [0x7f3d2d685bbc]\n[bt] (1) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2299e00) [0x7f3d2f7a1e00]\n[bt] (2) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x21f67b7) [0x7f3d2f6fe7b7]\n[bt] (3) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x20180ee) [0x7f3d2f5200ee]\n[bt] (4) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x201abc1) [0x7f3d2f522bc1]\n[bt] (5) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x1ffe5c9) [0x7f3d2f5065c9]\n[bt] (6) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x1fff084) [0x7f3d2f507084]\n[bt] (7) /home/ai_ja_nai/pischool/mxnet/venv3/local/lib/python3.5/site-packages/mxnet/libmxnet.so(MXExecutorSimpleBind+0x2300) [0x7f3d2f4946b0]\n[bt] (8) /home/ai_ja_nai/pischool/mxnet/venv3/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7f3d5c2d0e20]\n[bt] (9) /home/ai_ja_nai/pischool/mxnet/venv3/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7f3d5c2d088b]\n"
     ]
    }
   ],
   "source": [
    "model.fit(traindata_iterator,\n",
    "          eval_data=evaldata_iterator,\n",
    "          optimizer=mx.optimizer.Adam,\n",
    "          optimizer_params={'learning_rate': 0.1, 'momentum': 0.9},\n",
    "          eval_metric='acc',\n",
    "          num_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(spectrograms_count):\n",
    "    predicted_frames,decoder_state = decoder(predicted_frames,decoder_state,reduction_factor)\n",
    "    full_frame=mx.sym.concat(full_frame,predicted_frames)\n",
    "\n",
    "spectral_magnitude=CBHG(full_frame, 8, emb_size, 80)\n",
    "\n",
    "graph=mx.viz.plot_network(\n",
    "    spectral_magnitude,\n",
    "    save_format='pdf',\n",
    "    title='decoder')\n",
    "#graph.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
